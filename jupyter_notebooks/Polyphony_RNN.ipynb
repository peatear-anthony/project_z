{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](https://awl.co.jp/wp-content/themes/awl/img/img-header-logo.png)\n",
    "\n",
    "# AI Music Generator Project (Polyphony_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Settings\n",
    "*   **Number of Training Steps:**  Number of update steps to perform, before exiting the loop. This usually should be around 10000 to 20000.\n",
    "*   **Training/Evaluation Ratio:**  How to split your dataset. For example, a ratio of 10% will allocate 90% of your data to training and 10% of your data to evaluation.\n",
    "*   **Batch Size:** Number of examples used in one update step. This value will affect the speed of training. Recommended value is 64\n",
    "\n",
    "## Generate MIDIs from the Trained Model\n",
    "\n",
    "\n",
    "### Generation Settings\n",
    "*  **Output_Folder** : Name of the MIDI Output Folder. It is recommended to change the name for every individual run. For example, \"run1\", \"run2\", and so on...\n",
    "*  **Number_of_MIDIs** : Number of MIDI that will be generated\n",
    "* **Number_of_Steps** :  Length of each generated MIDI. Note that 128 steps is approximately 15 seconds. In addition, if the number of steps is too large, the model may experience difficulty generating the MIDI file.\n",
    "* **Primer_Pitches**: Also known as the **MIDI Note Number**. This is the note/chord which will start the generated sequence. Refer to the images below converting between MIDI Note Numbers and Note Names.\n",
    "\n",
    "![Pitches1](http://c2rexplugins.weebly.com/uploads/1/4/2/6/14264557/627278711.png)\n",
    "![Pitches2](https://raw.githubusercontent.com/Ilya-Simkin/MusicGuru-RNN-Composer/master/images/pianopitchMidi.jpg)\n",
    "\n",
    "[Alternate Reference #1 ](http://www.inspiredacoustics.com/en/MIDI_note_numbers_and_center_frequencies)\n",
    "\n",
    "[Alternate Reference #2 ](http://www.inspiredacoustics.com/en/MIDI_note_numbers_and_center_frequencies) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "training_steps = widgets.IntSlider(\n",
    "    value=500,\n",
    "    min=0,\n",
    "    max=4000,\n",
    "    step=10,\n",
    "    description='Training Steps:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "train_validation_percent = widgets.FloatSlider(\n",
    "    value=0.9,\n",
    "    min=0.1,\n",
    "    max=1,\n",
    "    step=0.05,\n",
    "    description='Train/Val Ratio',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    ")\n",
    "\n",
    "\n",
    "batch_size= widgets.RadioButtons(\n",
    "    options=['64', '128', '264'],\n",
    "    description='Batch Size:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "output_folder = widgets.Text(\n",
    "    value='run1',\n",
    "    placeholder='output folder name',\n",
    "    description='MIDI Generation Folder Name:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "num_midis = widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Num of Midis:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "Number_of_Steps = widgets.IntSlider(\n",
    "    value=128,\n",
    "    min=64,\n",
    "    max=1000,\n",
    "    step=64,\n",
    "    description='Number_of_Steps:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "primer_pitches = widgets.Text(\n",
    "        value=\"[60,63]\",\n",
    "        placeholder='Type something',\n",
    "        description='String:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "primer_pitch = str(primer_pitches.value)\n",
    "\n",
    "display(training_steps)\n",
    "display(train_validation_percent)\n",
    "display(batch_size)\n",
    "display(output_folder)\n",
    "display(num_midis)\n",
    "display(Number_of_Steps)\n",
    "display(primer_pitches)\n",
    "hide_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "drive_dir = \"/root/magenta-data\"\n",
    "\n",
    "training_dir = os.path.join(drive_dir,\"midi-data/training-set\")\n",
    "generated_midi_dir = os.path.join(drive_dir,\"midi-data/generated_data/polyphony_rnn\")\n",
    "\n",
    "note_dir = os.path.join(drive_dir,\"tmp\")\n",
    "seq_dir = os.path.join(drive_dir,\"tmp/polyphony_rnn/sequence_examples\")\n",
    "\n",
    "\n",
    "os.environ['TRAIN_SET_DIR'] = str(os.path.join(drive_dir,\"midi-data/training-set\"))\n",
    "os.environ['NOTESEQ_FILE'] = str(os.path.join(drive_dir,\"tmp/notesequences.tfrecord\"))\n",
    "os.environ['SEQ_DIR'] = str(os.path.join(drive_dir,\"tmp/polyphony_rnn/sequence_examples\"))\n",
    "os.environ['SEQ_FILE']= str(os.path.join(drive_dir,\"tmp/polyphony_rnn/sequence_examples/training_poly_tracks.tfrecord\"))\n",
    "os.environ['RUN_DIR'] = str(os.path.join(drive_dir,\"tmp/polyphony_rnn/logdir/run1\"))\n",
    "os.environ['OUTPUT_DIR'] = str(os.path.join(drive_dir,\"midi-data/generated_data/polyphony_rnn\"))\n",
    "\n",
    "\n",
    "os.environ['TRAINING_STEPS']=str(training_steps.value)\n",
    "os.environ['TRAIN_VAL_RATIO']= str(train_validation_percent.value)\n",
    "os.environ['BATCH_SIZE']=str(batch_size.value)\n",
    "\n",
    "#hparams\n",
    "hparams='batch_size='+str(batch_size.value) +\",rnn_layer_sizes=\"+str(\"[64,64]\")\n",
    "os.environ['HPARAMS']=hparams\n",
    "\n",
    "# generation\n",
    "generated_midi_dir_temp=os.path.join(generated_midi_dir, output_folder.value)\n",
    "\n",
    "os.environ['OUTPUT_DIR']= generated_midi_dir_temp\n",
    "os.environ['MIDI_OUTPUT']=str(num_midis.value)\n",
    "os.environ['GEN_STEPS']=str(Number_of_Steps.value)\n",
    "os.environ['PRIMER_PITCH']=primer_pitch\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert_dir_to_note_sequences \\\n",
    "--input_dir=\"$TRAIN_SET_DIR\" \\\n",
    "--output_file=\"$NOTESEQ_FILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!polyphony_rnn_create_dataset \\\n",
    "--input=\"$NOTESEQ_FILE\" \\\n",
    "--output_dir=\"$SEQ_DIR\" \\\n",
    "--eval_ratio=$TRAIN_VAL_RATIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!polyphony_rnn_train \\\n",
    "--run_dir=\"$RUN_DIR\" \\\n",
    "--sequence_example_file=\"$SEQ_FILE\" \\\n",
    "--hparams=$HPARAMS \\\n",
    "--num_training_steps=$TRAINING_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!polyphony_rnn_generate \\\n",
    "--run_dir=\"$RUN_DIR\" \\\n",
    "--hparams=$HPARAMS \\\n",
    "--output_dir=\"$OUTPUT_DIR\" \\\n",
    "--num_outputs=$MIDI_OUTPUT \\\n",
    "--num_steps=$GEN_STEPS \\\n",
    "--primer_pitches=$PRIMER_PITCH \\\n",
    "--condition_on_primer=true \\\n",
    "--inject_primer_during_generation=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
